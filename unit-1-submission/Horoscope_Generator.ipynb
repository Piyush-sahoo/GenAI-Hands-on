{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Daily Horoscope Generator**"
      ],
      "metadata": {
        "id": "ep48h7-6p--G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Input a zodiac sign and generate a vague but convincing fortune.\n",
        "\n",
        "Tech: gpt2 or distilgpt2."
      ],
      "metadata": {
        "id": "lxT1YcvKqqgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Bhavana Ramkumar\n",
        "\n",
        "SRN: PES2UG23CS905\n",
        "\n",
        "Section: B\n"
      ],
      "metadata": {
        "id": "vHa6Kfj8q2eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Hugging Face Transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvCIPcGRlq_R",
        "outputId": "9e125667-4416-419c-992b-a3ec3a49c977"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "set_seed(42)\n",
        "\n",
        "def generate_horoscope(sign):\n",
        "    prompt = (\n",
        "        f\"Daily Horoscope for {sign}:\\n\"\n",
        "        \"Today, the cosmic energies suggest a focus on inner reflection and personal growth. \"\n",
        "        \"Expect opportunities to connect with loved ones and express your true feelings. \"\n",
        "        \"In your career, a new challenge might arise, bringing a chance to shine. \"\n",
        "        \"Financially, be mindful of impulsive decisions. Your fortune today is:\\n\"\n",
        "    )\n",
        "\n",
        "    output = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=150, # Increased token limit for a more detailed horoscope\n",
        "        temperature=0.9,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        pad_token_id=50256,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    horoscope = output[0][\"generated_text\"].replace(prompt, \"\").strip()\n",
        "    return horoscope\n",
        "\n",
        "sign = \"Taurus\"\n",
        "print(f\"Horoscope for {sign}:\\n\")\n",
        "print(generate_horoscope(sign))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DtucEXfloMY",
        "outputId": "e118f06d-c078-4cc8-9fd7-34a3a8277bdf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horoscope for Taurus:\n",
            "\n",
            "The New York Times:\n",
            "This is a great opportunity for some individuals to reach out to you on a personal level. This might be a gift for one of you, or it might be an opportunity for others. The best example of an open exchange is a young woman who has been working out for eight days. In that moment, she starts to realize that her life is going to be in jeopardy if she does not talk about her work. She starts to think that she can never be as good as she wants.\n",
            "Growth is a great thing! One way to make the most of your life is to use your energy. Use energy to build your future. Build your self-confidence. When you want to stay focused, your energy may\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sign = \"Leo\"\n",
        "print(f\"Horoscope for {sign}:\\n\")\n",
        "print(generate_horoscope(sign))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMXwc1mnprl9",
        "outputId": "ee9eb9b3-71c5-4f45-95e1-82ee12bc1b50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horoscope for Leo:\n",
            "\n",
            "In your career, a new challenge might arise, bringing a chance to shine. Your fortune today is:\n",
            "An individual life, that's the most important, most personal, is in the forefront.\n",
            "The person you are at the moment is who you are most interested in, is most likely going to make the most out of their moment. And it's their true moment, not theirs.\n",
            "In your career, the most important, most personal, is in the forefront.\n",
            "You know that person, you know what they're going through, you know how important their life is and how important they are. And they are very, very happy.\n",
            "I'm very happy for you, I'm just happy, I'm just proud to be\n"
          ]
        }
      ]
    }
  ]
}