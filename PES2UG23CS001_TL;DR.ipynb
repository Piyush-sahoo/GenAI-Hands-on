{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37c8954",
   "metadata": {},
   "source": [
    "**TL;DR for News Articles**\n",
    "\n",
    "Goal: Paste a long news article URL or text and get a 3-sentence summary.\n",
    "\n",
    "Tech: distilbart for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a276dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (4.47.0)\n",
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keeru\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37337c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"sshleifer/distilbart-cnn-12-6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28ddab",
   "metadata": {},
   "source": [
    "- DistilBART is a lightweight encoder–decoder model optimized for summarization, offering a good balance between speed and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436aa009",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Generative Artificial Intelligence has rapidly evolved over the past decade and has become a transformative technology across multiple industries.\n",
    "It refers to AI systems that can generate new content such as text, images, audio, and videos that closely resemble human-created data.\n",
    "Popular applications of generative AI include chatbots, content creation tools, image generators, and automated code assistants.\n",
    "\n",
    "Despite its impressive capabilities, generative AI introduces several significant challenges and risks.\n",
    "One major concern is hallucination, where AI models generate information that appears plausible but is factually incorrect.\n",
    "Another issue is bias, as these models often learn and reproduce biases present in their training data.\n",
    "Additionally, generative AI has enabled the creation of deepfakes, which can be misused to spread misinformation, manipulate public opinion, or damage personal reputations.\n",
    "\n",
    "There are also ethical and legal concerns related to data privacy, copyright infringement, and accountability.\n",
    "Since many generative models are trained on large-scale internet data, questions arise regarding consent and ownership of the generated content.\n",
    "Governments, researchers, and organizations worldwide are actively discussing regulatory frameworks and ethical guidelines to ensure responsible and transparent use of generative AI technologies.\n",
    "\n",
    "As generative AI continues to advance, it is crucial to balance innovation with safety.\n",
    "Developing robust evaluation methods, improving model transparency, and promoting ethical AI practices will play a key role in shaping the future of artificial intelligence.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6b2436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " Generative Artificial Intelligence has become a transformative technology across multiple industries . It refers to AI systems that can generate new content such as text, images, audio, and videos that closely resemble human-created data . Popular applications of generative AI include chatbots, content creation tools, image generators\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer(\n",
    "    text,\n",
    "    max_length=60,\n",
    "    min_length=25,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f123eb1",
   "metadata": {},
   "source": [
    "This project implements a TL;DR **news summarizer** using **Hugging Face’s summarization** pipeline. A pre-trained DistilBART model is used to convert long input text into a concise summary. The project demonstrates the use of **encoder–decoder architectures** for abstractive summarization and highlights how pretrained models can be leveraged for real-world productivity applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
