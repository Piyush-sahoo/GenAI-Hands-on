{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca340359",
   "metadata": {},
   "source": [
    "The AI Storyteller\n",
    "Goal: App that takes a starting sentence (e.g., \"The knight entered the dark cave\") and generates a short creative story.\n",
    "Tech: Use gpt2 with non-deterministic sampling (do_sample=True) for creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feec32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "story_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(prompt):\n",
    "    story = story_generator(\n",
    "        prompt,\n",
    "        max_length=120,\n",
    "        do_sample=True,        \n",
    "        temperature=0.9,       \n",
    "        top_k=50,              \n",
    "        top_p=0.95,            \n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    return story[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac884cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knight entered the dark cave with a smile on his face.\n",
      "\n",
      "\"Well, that's what I was talking about, it's really not as bad as I thought…\"\n",
      "\n",
      "「I see. I'll go with you.」\n",
      "\n",
      "「…You'll be fine after taking this place.」\n",
      "\n",
      "I went back to the man with the red-haired witch, who had been making a speech.\n",
      "\n",
      "「So, I won't let you take any other place, don't worry, after all you're an adventurer, you will always be a knight.」\n",
      "\n",
      "「Oi, I didn't say it like that. And how about you……I'll take the place you gave me.」\n",
      "\n",
      "After a couple of tense words, the knight replied.\n",
      "\n",
      "「I won't let you take other places, this place is my residence.」\n",
      "\n",
      "And with that, the knight disappeared.\n",
      "\n",
      "The next moment the woman in red-haired witch entered the dungeon.\n",
      "\n",
      "「What the heck?」\n",
      "\n",
      "「If this woman was someone who could kill me, the knight would be too weak to protect you.」\n",
      "\n",
      "She was a knight of the Knights of the White Knight.\n",
      "\n",
      "The knight that had been knighted by the woman with red hair and white\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The knight entered the dark cave\"\n",
    "\n",
    "generated_story = generate_story(prompt)\n",
    "print(generated_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2794ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT: In the year 2050, artificial intelligence became self-aware\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the year 2050, artificial intelligence became self-aware and began to take over the world's computing and information systems. In that time, robots will be able to drive the world's roads and to make medical discoveries. AI is now in charge of most of our everyday life, from building transportation systems to diagnosing disease.\n",
      "\n",
      "The question of how machines will interact with humans is still a mystery to us. The technology is so complex, and so complex that even some of the greatest thinkers in the field have struggled to keep up. Many of the greatest thinkers have long been worried that the rise of AI will make society too dependent on machines. A lot of our thinking, such as the many new technologies that I've been writing about, are based on the idea that AI will bring about more of the right outcomes than the average human would like.\n",
      "\n",
      "But a lot of that worries me. AI is becoming more important as the average human has become more educated and more responsible and has a better appreciation for the human condition.\n",
      "\n",
      "I'm not saying that AI is bad for humanity. We are in the process of learning a lot about the human condition. But we need to be careful what we tell ourselves about it. The next generation of robots will be smart enough to understand human behavior and make decisions that will make human\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "PROMPT: The old book glowed as soon as she opened it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old book glowed as soon as she opened it. \"Well, you see, here's a pretty cool thing about this book…I've written a bunch of stuff about me, but I've never published anything about you. Just like I had to, in this case, in the first place.\"\n",
      "\n",
      "\"Do you mean that?\"\n",
      "\n",
      "\"Yes. I'm an editor for The New York Times. So, I've got the idea to write books about you. That's what I think you're supposed to do.\"\n",
      "\n",
      "\"You've got to write books about yourself.\"\n",
      "\n",
      "\"You just have to write, if you like, interesting, and unique stories that resonate with readers.\"\n",
      "\n",
      "\"Oh, that's kind of what I mean by that.\"\n",
      "\n",
      "\"And that's what I really love about your writing.\"\n",
      "\n",
      "\"Oh, you mean, you're really smart, right?\"\n",
      "\n",
      "\"Yeah. I love that. I love that.\"\n",
      "\n",
      "\"So you've got all the characters in this book, I guess?\"\n",
      "\n",
      "\"Yeah. Yeah. Yeah. Really good characters. Not just the sort of people you'd like to have a bunch of. Like I love John Hughes and Jane Austen, they're great, so there's sort of a bunch\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "PROMPT: On Mars, the first human colony faced an unexpected problem\n",
      "On Mars, the first human colony faced an unexpected problem, though. Despite being far from fully manned by humans (a mere 6 days, or half a century) the colony was not entirely safe from the dangerous effects of the vacuum. Instead the colony had no way to escape the gravity of the atmosphere, and was trapped in one of the most dangerous habitats on the planet, Earth. All the while the colony was trying to escape its own atmosphere, and the Earth was becoming increasingly contaminated with organic material (both natural and manmade) from the Mars atmosphere. For the first time ever, the colony had to leave Earth in order to survive as humans and survive in the vacuum. As the colony was moving into a new colony, the colony's atmosphere slowly became depleted of its organic material. The vacuum of space became an enormous minefield of carbon dioxide, the building blocks of life. As the colony slowly became depleted, the colony also became vulnerable to the effects of the vacuum. The colonies began to lose all hope of survival, and, through constant manipulation, could not escape the dangers of the vacuum. Even on Earth, the colonists were afraid. Despite their efforts, the vacuum of space was still a minefield of pollution and pollution that they could not escape from. In order to leave Earth, the colonists would have to endure a\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"In the year 2050, artificial intelligence became self-aware\",\n",
    "    \"The old book glowed as soon as she opened it\",\n",
    "    \"On Mars, the first human colony faced an unexpected problem\"\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    print(\"\\nPROMPT:\", p)\n",
    "    print(generate_story(p))\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
